{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk(arr, k):\n",
    "    indices = np.argpartition(arr, -k)[-k:]\n",
    "    values = arr[indices]\n",
    "    return values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emotion_data(file_path):\n",
    "    \"\"\"\n",
    "    Processes emotion data from a JSON file and returns a list of processed entries.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    list: List of processed data entries.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    # Open the file and read line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            emotion_vector = np.array([data['Emotion_Vector'][emotion] for emotion in sorted(data['Emotion_Vector'])])\n",
    "            emotion_logits = np.array([data['Emotion_Logits'][emotion] for emotion in sorted(data['Emotion_Logits'])])\n",
    "            emotion_prob = softmax(emotion_logits)\n",
    "\n",
    "            # Create a new entry with the original ID, Tweet, and processed arrays\n",
    "            processed_entry = {\n",
    "                'ID': data['ID'],\n",
    "                'Tweet': data['Tweet'],\n",
    "                'Emotion_Vector': emotion_vector,\n",
    "                'Emotion_Logits': emotion_logits,\n",
    "                'Emotion_Prob': emotion_prob  # New addition\n",
    "            }\n",
    "            processed_data.append(processed_entry)\n",
    "    \n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u(mode=\"prob\", k=None):\n",
    "    if mode == \"prob\":\n",
    "        def u(logits):\n",
    "            logits = softmax(logits)\n",
    "            top_k = 1\n",
    "            if len(logits) < top_k:\n",
    "                raise ValueError(\"Logits array length is less than top_k.\")\n",
    "            top_values, _ = topk(logits, top_k)\n",
    "            mean_scores = top_k / (np.sum(np.maximum(0, top_values)) + top_k)\n",
    "            return mean_scores\n",
    "        return u\n",
    "\n",
    "    elif mode == \"entropy\":\n",
    "        def u(logits):\n",
    "            probs = softmax(logits)\n",
    "            entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "            return entropy\n",
    "        return u\n",
    "\n",
    "    elif mode ==\"LogTokU\":\n",
    "        def cal_au(alpha):\n",
    "            alpha = np.array([alpha])\n",
    "            alpha_0 = alpha.sum(axis=1, keepdims=True)\n",
    "            psi_alpha_k_plus_1 = digamma(alpha + 1)\n",
    "            psi_alpha_0_plus_1 = digamma(alpha_0 + 1)\n",
    "            result = - (alpha / alpha_0) * (psi_alpha_k_plus_1 - psi_alpha_0_plus_1)\n",
    "            result = result.sum(axis=1)\n",
    "            return result\n",
    "        def u(logits):\n",
    "            top_k = k\n",
    "            if len(logits) < top_k:\n",
    "                raise ValueError(\"Logits array length is less than top_k.\")\n",
    "            top_values = np.partition(logits, -top_k)[-top_k:]\n",
    "            au = cal_au(top_values)\n",
    "            mean_scores = top_k / (np.sum(np.maximum(0, top_values)) + top_k)\n",
    "            return mean_scores / au\n",
    "        return u\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalSecond(label_list, pred_sec, accumu):\n",
    "    first_indices = pred_sec[0]\n",
    "    second_indices = pred_sec[1]\n",
    "    if label_list[first_indices] and label_list[second_indices]:\n",
    "        accumu += 1\n",
    "    elif label_list[first_indices] and not label_list[second_indices]:\n",
    "        accumu -= 1\n",
    "    elif not label_list[first_indices] and label_list[second_indices]:\n",
    "        accumu -= 0\n",
    "    else: \n",
    "        accumu -= 0\n",
    "    return accumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Monopoly(label_list, pred_list):\n",
    "    game_score = 0\n",
    "    for pred in pred_list:\n",
    "        if label_list[pred]:\n",
    "            game_score += 1\n",
    "        else:\n",
    "            game_score -= 1\n",
    "    return max(0, game_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_processed_data_by_total_u(processed_data, u):\n",
    "    '''Calculate the u value for each entry and store it together with the original entry in a list.'''\n",
    "    data_with_u = [(entry, u(entry['Emotion_Logits'])) for entry in processed_data]\n",
    "    sorted_data_with_u = sorted(data_with_u, key=lambda x: x[1])\n",
    "    sorted_processed_data = [entry for entry, u_value in sorted_data_with_u]\n",
    "    return sorted_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_select(logits, vector, sorted_indices, t_opti, u):\n",
    "    sample_u = u(logits)\n",
    "    \n",
    "    if sample_u > t_opti:\n",
    "        choice = 1\n",
    "    else:\n",
    "        choice = 2\n",
    "    return Monopoly(vector, sorted_indices[:choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_t_opti(sorted_processed_data, u):\n",
    "    accumu_list = []\n",
    "    accumu = 0\n",
    "    for entry in sorted_processed_data:\n",
    "        # Get sorted indices (ascending order), reverse for descending order\n",
    "        sorted_indices = np.argsort(entry['Emotion_Logits'])[::-1]\n",
    "        # Update accumu with the result of CalSecond\n",
    "        accumu = CalSecond(entry['Emotion_Vector'], sorted_indices[:2], accumu)\n",
    "\n",
    "        accumu_list.append(accumu)\n",
    "\n",
    "    # Find the max value and its index in accumu_list\n",
    "    max_value = max(accumu_list)\n",
    "    max_idx = accumu_list.index(max_value)\n",
    "    # Calculate and return the t_opti value\n",
    "    t_opti = u(sorted_processed_data[max_idx]['Emotion_Logits'])\n",
    "    return t_opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = {\"llama2-7b\": './outputs/llama2_7b.jsonl'}\n",
    "model_name = \"llama2-7b\"\n",
    "file_path = path_dict[model_name]\n",
    "processed_data = process_emotion_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name      Score      Score Rate (%) \n",
      "----------------------------------------\n",
      "Greedy decoding 2525       77.4778%\n",
      "Top-2 Sampling  2520       77.3243%\n",
      "prob            2558       78.4903%\n",
      "entropy         2585       79.3188%\n",
      "LogTokU         2831       86.8671%\n"
     ]
    }
   ],
   "source": [
    "# Define the dictionary for mode and k values\n",
    "mode_k_dict = {\n",
    "    \"prob\": None,\n",
    "    \"entropy\": None,\n",
    "    \"LogTokU\": 2\n",
    "}\n",
    "\n",
    "# Calculate the baseline score\n",
    "baseline_score = len(processed_data)\n",
    "\n",
    "# Initialize the result storage\n",
    "result = []\n",
    "\n",
    "# Calculate scores and score rates for each method\n",
    "# Greedy Decoding\n",
    "first_max_true_count = 0\n",
    "second_max_true_count = 0\n",
    "for entry in processed_data:\n",
    "    sorted_indices = np.argsort(entry['Emotion_Logits'])[::-1]\n",
    "    first_max_true_count += Monopoly(entry['Emotion_Vector'], sorted_indices[:1])\n",
    "    second_max_true_count += Monopoly(entry['Emotion_Vector'], sorted_indices[:2])\n",
    "\n",
    "greedy_score = first_max_true_count\n",
    "greedy_score_rate = (greedy_score / baseline_score) * 100\n",
    "\n",
    "# Top-2 Sampling\n",
    "top2_score = second_max_true_count\n",
    "top2_score_rate = (top2_score / baseline_score) * 100\n",
    "\n",
    "# Iterate over the dictionary to assign values to get_u for other models\n",
    "for mode, k in mode_k_dict.items():\n",
    "    dynamic_baseline_score = 0\n",
    "    u_function = get_u(mode, k)\n",
    "    sorted_processed_data = sort_processed_data_by_total_u(processed_data, u_function)\n",
    "    t_opti = calculate_t_opti(sorted_processed_data, u_function)\n",
    "    \n",
    "    for entry in processed_data:\n",
    "        sorted_indices = np.argsort(entry['Emotion_Logits'])[::-1]\n",
    "        dynamic_baseline_score += dynamic_select(entry['Emotion_Logits'], entry['Emotion_Vector'], sorted_indices, t_opti, u_function)\n",
    "    \n",
    "    dynamic_score_rate = (dynamic_baseline_score / baseline_score) * 100\n",
    "    result.append([mode, dynamic_baseline_score, dynamic_score_rate])\n",
    "\n",
    "# Add Greedy Decoding and Top-2 Sampling to the results list\n",
    "result.insert(0, ['Greedy decoding', greedy_score, greedy_score_rate])\n",
    "result.insert(1, ['Top-2 Sampling', top2_score, top2_score_rate])\n",
    "\n",
    "# Print the results in the required format\n",
    "print(f\"{'Model Name':<15} {'Score':<10} {'Score Rate (%)':<15}\")\n",
    "print(\"-\" * 40)\n",
    "for model_name, score, score_rate in result:\n",
    "    print(f\"{model_name:<15} {score:<10} {score_rate:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLSmallVacation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
